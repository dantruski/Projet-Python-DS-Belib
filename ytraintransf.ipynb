{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce code est de modifier comme il se doit le data set ytrain pour avoir des données par heures et dans un carré\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "\n",
    "from branca.colormap import linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16902/548241558.py:1: DtypeWarning: Columns (1,3,5,11,20,49,52,54,55,56,64,70,71,94,95,101,102,114,129,131,132,133,138,139,152,157,163,174,180,184,193,196,201,207,208,219,220,228,241,245,250,256,258,264,265,269,270,271,272,273) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"ytrain_NpxebDC.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"ytrain_NpxebDC.csv\")\n",
    "df_real = pd.DataFrame(data)\n",
    "data_stat = pd.read_csv(\"info_static.csv\")\n",
    "df_stat = pd.DataFrame(data_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16902/2492042055.py:6: DtypeWarning: Columns (1,3,5,11,20,49,52,54,55,56,64,70,71,94,95,101,102,114,129,131,132,133,138,139,152,157,163,174,180,184,193,196,201,207,208,219,220,228,241,245,250,256,258,264,265,269,270,271,272,273) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"ytrain_NpxebDC.csv\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m_zmq.py:160\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython._zmq.Frame.__del__'\n",
      "Traceback (most recent call last):\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Charger les datasets\n",
    "data = pd.read_csv(\"ytrain_NpxebDC.csv\")\n",
    "df_real = pd.DataFrame(data)\n",
    "\n",
    "data_stat = pd.read_csv(\"info_static.csv\")\n",
    "\n",
    "# Nettoyage des données de latitude et longitude dans data_stat\n",
    "data_stat['latitude'] = pd.to_numeric(data_stat['latitude'], errors='coerce')\n",
    "data_stat['longitude'] = pd.to_numeric(data_stat['longitude'], errors='coerce')\n",
    "\n",
    "# Définir les limites de la grille (basé sur Paris)\n",
    "lat_min, lat_max = 48.81, 48.92\n",
    "lon_min, lon_max = 2.255, 2.42\n",
    "step = 0.005  # Taille d'un carré (grille de 0.005°)\n",
    "\n",
    "# Fonction pour créer la grille\n",
    "def creer_grille(lat_min, lat_max, lon_min, lon_max, step):\n",
    "    grille = []\n",
    "    latitudes = np.arange(lat_min, lat_max, step)\n",
    "    longitudes = np.arange(lon_min, lon_max, step)\n",
    "    \n",
    "    for i in range(len(latitudes) - 1):\n",
    "        for j in range(len(longitudes) - 1):\n",
    "            carre = {\n",
    "                \"id\": f\"{i}_{j}\",\n",
    "                \"lat_min\": latitudes[i],\n",
    "                \"lat_max\": latitudes[i + 1],\n",
    "                \"lon_min\": longitudes[j],\n",
    "                \"lon_max\": longitudes[j + 1],\n",
    "                \"lati\": latitudes[i] + step / 2,  # Centre du carré\n",
    "                \"long\": longitudes[j] + step / 2  # Centre du carré\n",
    "            }\n",
    "            grille.append(carre)\n",
    "    return grille\n",
    "\n",
    "# Fonction pour trouver le carré correspondant à un point\n",
    "def trouver_carre(lat, lon, grille):\n",
    "    if pd.isnull(lat) or pd.isnull(lon):  # Vérifier si lat ou lon est NaN\n",
    "        return None, None, None\n",
    "    for carre in grille:\n",
    "        if carre[\"lat_min\"] <= lat < carre[\"lat_max\"] and carre[\"lon_min\"] <= lon < carre[\"lon_max\"]:\n",
    "            return carre[\"id\"], carre[\"lati\"], carre[\"long\"]\n",
    "    return None, None, None\n",
    "\n",
    "# Fonction pour associer les carrés à chaque point GPS\n",
    "def associer_carres(df, grille):\n",
    "    df[['carre_id', 'lati', 'long']] = df.apply(\n",
    "        lambda row: pd.Series(trouver_carre(row['latitude'], row['longitude'], grille)), axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Créer la grille\n",
    "grille = creer_grille(lat_min, lat_max, lon_min, lon_max, step)\n",
    "\n",
    "# Associer les carrés pour le dataset statique (info_static)\n",
    "data_stat = associer_carres(data_stat, grille)\n",
    "\n",
    "# Extraire les identifiants uniques pour correspondre les datasets\n",
    "df_real['timestamp'] = pd.to_datetime(df_real['timestamp'])  # Convertir en datetime\n",
    "df_real_long = df_real.melt(id_vars=['timestamp'], var_name='t_id', value_name='status')\n",
    "\n",
    "# Ajouter les informations statiques (latitude, longitude, adresse, etc.) à partir de data_stat\n",
    "df_real_long = df_real_long.merge(\n",
    "    data_stat[['t_id', 'latitude', 'longitude', 'street', 'city', 'zipcode', 'model']],\n",
    "    on='t_id', how='left'\n",
    ")\n",
    "\n",
    "# Ajouter les informations de la grille au dataset final\n",
    "df_real_long = associer_carres(df_real_long, grille)\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes critiques\n",
    "df_real_long = df_real_long.dropna(subset=['latitude', 'longitude', 'carre_id'])\n",
    "\n",
    "# Afficher un aperçu du DataFrame final\n",
    "print(df_real_long.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper les données par carré et t_1h, puis calculer la moyenne de k\n",
    "resultats_groupes = merged_df.groupby(['timestamp','carre_id']).agg(\n",
    "    moyenne_k=('k', 'mean'),\n",
    "    somme_k=('k', 'sum'),\n",
    "    count_k=('k', 'count'),\n",
    "    lati= ('lati', 'mean'),\n",
    "    long= ('long', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(resultats_groupes['moyenne_k'].max())\n",
    "resultats_groupes.head(10)\n",
    "print(resultats_groupes['moyenne_k'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le DataFrame final dans un nouveau fichier CSV\n",
    "df_real_long.to_csv(\"dataset_complet.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
