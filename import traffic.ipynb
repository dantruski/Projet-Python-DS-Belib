{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé : comptages_routiers_2020.zip\n",
      "Deux premiers fichiers extraits : ['trafic_capteurs_2020_W00_20200101_20200108.txt', 'trafic_capteurs_2020_W01_20200108_20200115.txt']\n",
      "Fichier converti en JSON : extracted_data/trafic_capteurs_2020_W00_20200101_20200108.json\n",
      "Fichier converti en JSON : extracted_data/trafic_capteurs_2020_W01_20200108_20200115.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "# URL du fichier ZIP\n",
    "url = \"https://opendata.paris.fr/api/datasets/1.0/comptages-routiers-permanents-historique/attachments/opendata_txt_2020_zip/\"\n",
    "\n",
    "# Nom local du fichier ZIP\n",
    "zip_filename = \"comptages_routiers_2020.zip\"\n",
    "\n",
    "# Dossier où extraire les fichiers\n",
    "output_folder = \"extracted_data\"\n",
    "\n",
    "# Étape 1 : Télécharger le fichier ZIP\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(zip_filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier téléchargé : {zip_filename}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement : {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Étape 2 : Extraire le contenu du fichier ZIP\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    all_files = zip_ref.namelist()[:2]  # Limiter à 2 fichiers\n",
    "    for file in all_files:\n",
    "        zip_ref.extract(file, output_folder)\n",
    "    print(f\"Deux premiers fichiers extraits : {all_files}\")\n",
    "\n",
    "# Étape 3 : Convertir les fichiers texte en JSON\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(output_folder, file)\n",
    "    if file.endswith(\".txt\"):  # Assurez-vous que le fichier est un fichier texte\n",
    "        try:\n",
    "            json_data = []\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                # Lire le fichier ligne par ligne et convertir en JSON\n",
    "                for line in f:\n",
    "                    data = line.strip().split(\"\\t\")  # Séparer les données par tabulation\n",
    "                    json_data.append(data)\n",
    "            \n",
    "            # Sauvegarder les données en JSON\n",
    "            json_filename = file_path.replace(\".txt\", \".json\")\n",
    "            with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(json_data, json_file, indent=4)\n",
    "            print(f\"Fichier converti en JSON : {json_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement du fichier {file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation de la table référentiel en csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé et sauvegardé sous : referentiel.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL du fichier CSV que vous voulez télécharger\n",
    "url = 'https://parisdata.opendatasoft.com/api/explore/v2.1/catalog/datasets/referentiel-comptages-routiers/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B'\n",
    "\n",
    "# Nom local sous lequel vous voulez sauvegarder le fichier\n",
    "local_filename = 'referentiel.csv'\n",
    "\n",
    "# Télécharger le fichier\n",
    "response = requests.get(url)\n",
    "\n",
    "# Vérifier si la demande a réussi (status_code 200)\n",
    "if response.status_code == 200:\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier téléchargé et sauvegardé sous : {local_filename}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement du fichier : {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifiant arc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6799</td>\n",
       "      <td>48.88610804018005</td>\n",
       "      <td>2.3060170797614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6839</td>\n",
       "      <td>48.882846124767354</td>\n",
       "      <td>2.309608336489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6381</td>\n",
       "      <td>48.88185021600981</td>\n",
       "      <td>2.313636877615184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240</td>\n",
       "      <td>48.867653082202935</td>\n",
       "      <td>2.362827833173667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5164</td>\n",
       "      <td>48.83748471020789</td>\n",
       "      <td>2.2572392666841106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6603</td>\n",
       "      <td>48.82680441725183</td>\n",
       "      <td>2.3040355371176604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6593</td>\n",
       "      <td>48.86194217627273</td>\n",
       "      <td>2.31342704120477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6813</td>\n",
       "      <td>48.85824539762091</td>\n",
       "      <td>2.314401975386383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4382</td>\n",
       "      <td>48.87468482154655</td>\n",
       "      <td>2.303280892510164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>269</td>\n",
       "      <td>48.86779977023447</td>\n",
       "      <td>2.314350336430965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifiant arc                 lat                  lon\n",
       "0             6799   48.88610804018005   2.3060170797614274\n",
       "1             6839  48.882846124767354    2.309608336489109\n",
       "2             6381   48.88185021600981    2.313636877615184\n",
       "3             1240  48.867653082202935    2.362827833173667\n",
       "4             5164   48.83748471020789   2.2572392666841106\n",
       "5             6603   48.82680441725183   2.3040355371176604\n",
       "6             6593   48.86194217627273     2.31342704120477\n",
       "7             6813   48.85824539762091    2.314401975386383\n",
       "8             4382   48.87468482154655    2.303280892510164\n",
       "9              269   48.86779977023447    2.314350336430965"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Charger le fichier du référentiel avec les informations géographiques\n",
    "geo_df = pd.read_csv(\"referentiel.csv\", delimiter=\";\")\n",
    "geo_df[['lat', 'lon']] = geo_df['geo_point_2d'].str.split(',', expand=True)\n",
    "geo_df = geo_df[['Identifiant arc','lat', 'lon']]\n",
    "# Afficher les premières lignes pour vérifier la structure\n",
    "geo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier trafic_capteurs_2020_W00_20200101_20200108.txt chargé avec succès\n",
      "   iu_ac    k                 t_1h\n",
      "0    799  0.0  2020-01-01 01:00:00\n",
      "1    799  0.0  2020-01-01 02:00:00\n",
      "2    799  0.0  2020-01-01 03:00:00\n",
      "3    799  0.0  2020-01-01 04:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trafic_df = pd.read_csv(\"extracted_data/trafic_capteurs_2020_W00_20200101_20200108.txt\", delimiter=\";\")\n",
    "    print(\"Fichier trafic_capteurs_2020_W00_20200101_20200108.txt chargé avec succès\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du fichier trafic_capteurs_2020_W00_20200101_20200108.txt : {e}\")\n",
    "\n",
    "trafic_df = trafic_df[['iu_ac','k','t_1h']]\n",
    "trafic_df ['k'] = trafic_df ['k'].fillna(0)\n",
    "print(trafic_df.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iu_ac</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6799</td>\n",
       "      <td>48.88610804018005</td>\n",
       "      <td>2.3060170797614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6839</td>\n",
       "      <td>48.882846124767354</td>\n",
       "      <td>2.309608336489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6381</td>\n",
       "      <td>48.88185021600981</td>\n",
       "      <td>2.313636877615184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240</td>\n",
       "      <td>48.867653082202935</td>\n",
       "      <td>2.362827833173667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iu_ac                 lat                  lon\n",
       "0   6799   48.88610804018005   2.3060170797614274\n",
       "1   6839  48.882846124767354    2.309608336489109\n",
       "2   6381   48.88185021600981    2.313636877615184\n",
       "3   1240  48.867653082202935    2.362827833173667"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.rename(columns={\"Identifiant arc\": \"iu_ac\"}, inplace=True)\n",
    "geo_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire la jointure sur un identifiant commun (par exemple, 'iu_ac')\n",
    "merged_df = pd.merge(trafic_df, geo_df, on='iu_ac', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iu_ac      int64\n",
      "k        float64\n",
      "t_1h      object\n",
      "lat       object\n",
      "lon       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Afficher les premières lignes du DataFrame fusionné\n",
    "merged_df.head(2)\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la grille à partir des latitudes et longitudes\n",
    "def creer_grille(lat_min, lat_max, lon_min, lon_max, step):\n",
    "    grille = []\n",
    "    latitudes = np.arange(lat_min, lat_max, step)\n",
    "    longitudes = np.arange(lon_min, lon_max, step)\n",
    "    \n",
    "    for i in range(len(latitudes) - 1):\n",
    "        for j in range(len(longitudes) - 1):\n",
    "            carre = {\n",
    "                \"id\": f\"{i}_{j}\",  # Identifiant unique pour chaque carré\n",
    "                \"lat_min\": latitudes[i],\n",
    "                \"lat_max\": latitudes[i + 1],\n",
    "                \"lon_min\": longitudes[j],\n",
    "                \"lon_max\": longitudes[j + 1],\n",
    "                \"lati\": latitudes[i] + step,\n",
    "                \"long\": longitudes[j] + step,\n",
    "            }\n",
    "            grille.append(carre)\n",
    "    return grille\n",
    "\n",
    "# Fonction pour trouver le carré correspondant à un point\n",
    "def trouver_carre(lat, lon, grille):\n",
    "    if lat is None or lon is None:\n",
    "        return None\n",
    "    for carre in grille:\n",
    "        if carre[\"lat_min\"] <= lat < carre[\"lat_max\"] and carre[\"lon_min\"] <= lon < carre[\"lon_max\"]:\n",
    "            return carre[\"id\"],carre[\"lati\"],carre[\"long\"]\n",
    "    return None\n",
    "\n",
    "# Définir les limites de la grille\n",
    "lat_min, lat_max = 48.81, 48.92\n",
    "lon_min, lon_max = 2.255, 2.42\n",
    "step = 0.005  # Pas pour la grille, correspond à la taille d'un carré\n",
    "\n",
    "# Créer la grille\n",
    "grille = creer_grille(lat_min, lat_max, lon_min, lon_max, step)\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour associer le carré à chaque ligne du DataFrame\n",
    "def associer_carres(df):\n",
    "    df['carre_id'], df['lati'], df['long'] = df.apply(lambda row: trouver_carre(row['lat'], row['lon'], grille), axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Nettoyage des espaces dans lat et lon\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      3\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Conversion en float avec gestion des erreurs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Nettoyage des espaces dans lat et lon\n",
    "merged_df['lat'] = merged_df['lat'].str.strip()\n",
    "merged_df['lon'] = merged_df['lon'].str.strip()\n",
    "\n",
    "# Conversion en float avec gestion des erreurs\n",
    "merged_df['lat'] = pd.to_numeric(merged_df['lat'], errors='coerce')\n",
    "merged_df['lon'] = pd.to_numeric(merged_df['lon'], errors='coerce')\n",
    "\n",
    "# Supprimer les lignes avec des NaN dans lat ou lon\n",
    "merged_df = merged_df.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "# Appliquer la fonction pour associer les carrés\n",
    "merged_df['carre_id'], merged_df['lati'], merged_df['long'] = merged_df.apply(lambda row: trouver_carre(row['lat'], row['lon'], grille), axis=1)\n",
    "\n",
    "# Supprimer les lignes où carre_id est NaN\n",
    "merged_df = merged_df.dropna(subset=['carre_id'])\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iu_ac    k                 t_1h        lat       lon carre_id    lati  long\n",
      "0    799  0.0  2020-01-01 01:00:00  48.820906  2.355258     2_20  48.825  2.36\n",
      "1    799  0.0  2020-01-01 02:00:00  48.820906  2.355258     2_20  48.825  2.36\n",
      "2    799  0.0  2020-01-01 03:00:00  48.820906  2.355258     2_20  48.825  2.36\n",
      "3    799  0.0  2020-01-01 04:00:00  48.820906  2.355258     2_20  48.825  2.36\n",
      "4    799  0.0  2020-01-01 05:00:00  48.820906  2.355258     2_20  48.825  2.36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la grille à partir des latitudes et longitudes\n",
    "def creer_grille(lat_min, lat_max, lon_min, lon_max, step):\n",
    "    grille = []\n",
    "    latitudes = np.arange(lat_min, lat_max, step)\n",
    "    longitudes = np.arange(lon_min, lon_max, step)\n",
    "    \n",
    "    for i in range(len(latitudes) - 1):\n",
    "        for j in range(len(longitudes) - 1):\n",
    "            carre = {\n",
    "                \"id\": f\"{i}_{j}\",  # Identifiant unique pour chaque carré\n",
    "                \"lat_min\": latitudes[i],\n",
    "                \"lat_max\": latitudes[i + 1],\n",
    "                \"lon_min\": longitudes[j],\n",
    "                \"lon_max\": longitudes[j + 1],\n",
    "                \"lati\": latitudes[i] + 0.005,  # Centre du carré\n",
    "                \"long\": longitudes[j] +  0.005,  # Centre du carré\n",
    "            }\n",
    "            grille.append(carre)\n",
    "    return grille\n",
    "\n",
    "# Fonction pour trouver le carré correspondant à un point\n",
    "def trouver_carre(lat, lon, grille):\n",
    "    if pd.isnull(lat) or pd.isnull(lon):  # Vérifier si lat ou lon est NaN\n",
    "        return None, None, None\n",
    "    for carre in grille:\n",
    "        if carre[\"lat_min\"] <= lat < carre[\"lat_max\"] and carre[\"lon_min\"] <= lon < carre[\"lon_max\"]:\n",
    "            return carre[\"id\"], carre[\"lati\"], carre[\"long\"]\n",
    "    return None, None, None\n",
    "\n",
    "# Fonction pour associer le carré à chaque ligne du DataFrame\n",
    "def associer_carres(df, grille):\n",
    "    # Appliquer la fonction trouver_carre à chaque ligne\n",
    "    df[['carre_id', 'lati', 'long']] = df.apply(\n",
    "        lambda row: pd.Series(trouver_carre(row['lat'], row['lon'], grille)), axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Définir les limites de la grille\n",
    "lat_min, lat_max = 48.81, 48.92\n",
    "lon_min, lon_max = 2.255, 2.42\n",
    "step = 0.005  # Taille d'un carré\n",
    "\n",
    "# Créer la grille\n",
    "grille = creer_grille(lat_min, lat_max, lon_min, lon_max, step)\n",
    "\n",
    "\n",
    "# Nettoyer les colonnes lat et lon\n",
    "merged_df['lat'] = merged_df['lat'].astype(str).str.strip()\n",
    "merged_df['lon'] = merged_df['lon'].astype(str).str.strip()\n",
    "\n",
    "# Convertir les colonnes lat et lon en float\n",
    "merged_df['lat'] = pd.to_numeric(merged_df['lat'], errors='coerce')\n",
    "merged_df['lon'] = pd.to_numeric(merged_df['lon'], errors='coerce')\n",
    "\n",
    "# Supprimer les lignes avec des NaN dans lat ou lon\n",
    "merged_df = merged_df.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "# Associer les carrés\n",
    "merged_df = associer_carres(merged_df, grille)\n",
    "\n",
    "# Supprimer les lignes où carre_id est NaN\n",
    "merged_df = merged_df.dropna(subset=['carre_id'])\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carre_id</th>\n",
       "      <th>t_1h</th>\n",
       "      <th>moyenne_k</th>\n",
       "      <th>somme_k</th>\n",
       "      <th>count_k</th>\n",
       "      <th>lati</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 05:00:00</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 06:00:00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 07:00:00</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 09:00:00</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 10:00:00</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2</td>\n",
       "      <td>48.815</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  carre_id                 t_1h  moyenne_k  somme_k  count_k    lati  long\n",
       "0     0_16  2020-01-01 01:00:00      0.650     1.30        2  48.815  2.34\n",
       "1     0_16  2020-01-01 02:00:00      0.725     1.45        2  48.815  2.34\n",
       "2     0_16  2020-01-01 03:00:00      0.925     1.85        2  48.815  2.34\n",
       "3     0_16  2020-01-01 04:00:00      1.125     2.25        2  48.815  2.34\n",
       "4     0_16  2020-01-01 05:00:00      0.825     1.65        2  48.815  2.34\n",
       "5     0_16  2020-01-01 06:00:00      0.875     1.75        2  48.815  2.34\n",
       "6     0_16  2020-01-01 07:00:00      0.725     1.45        2  48.815  2.34\n",
       "7     0_16  2020-01-01 08:00:00      0.475     0.95        2  48.815  2.34\n",
       "8     0_16  2020-01-01 09:00:00      0.475     0.95        2  48.815  2.34\n",
       "9     0_16  2020-01-01 10:00:00      0.700     1.40        2  48.815  2.34"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regrouper les données par carré et t_1h, puis calculer la moyenne de k\n",
    "resultats_groupes = merged_df.groupby(['carre_id', 't_1h']).agg(\n",
    "    moyenne_k=('k', 'mean'),\n",
    "    somme_k=('k', 'sum'),\n",
    "    count_k=('k', 'count'),\n",
    "    lati= ('lati', 'mean'),\n",
    "    long= ('long', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "resultats_groupes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h.csv'\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les résultats dans un fichier CSV\n",
    "resultats_groupes.to_csv('moyennes_par_carre_et_t1h.csv', index=False)\n",
    "\n",
    "print(\"Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
