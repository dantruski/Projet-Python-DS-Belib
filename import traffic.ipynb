{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé : comptages_routiers_2020.zip\n",
      "Deux premiers fichiers extraits : ['trafic_capteurs_2020_W00_20200101_20200108.txt', 'trafic_capteurs_2020_W01_20200108_20200115.txt']\n",
      "Fichier converti en JSON : extracted_data/trafic_capteurs_2020_W00_20200101_20200108.json\n",
      "Fichier converti en JSON : extracted_data/trafic_capteurs_2020_W01_20200108_20200115.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "# URL du fichier ZIP\n",
    "url = \"https://opendata.paris.fr/api/datasets/1.0/comptages-routiers-permanents-historique/attachments/opendata_txt_2020_zip/\"\n",
    "\n",
    "# Nom local du fichier ZIP\n",
    "zip_filename = \"comptages_routiers_2020.zip\"\n",
    "\n",
    "# Dossier où extraire les fichiers\n",
    "output_folder = \"extracted_data\"\n",
    "\n",
    "# Étape 1 : Télécharger le fichier ZIP\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(zip_filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier téléchargé : {zip_filename}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement : {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Étape 2 : Extraire le contenu du fichier ZIP\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    all_files = zip_ref.namelist()[:2]  # Limiter à 2 fichiers\n",
    "    for file in all_files:\n",
    "        zip_ref.extract(file, output_folder)\n",
    "    print(f\"Deux premiers fichiers extraits : {all_files}\")\n",
    "\n",
    "# Étape 3 : Convertir les fichiers texte en JSON\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(output_folder, file)\n",
    "    if file.endswith(\".txt\"):  # Assurez-vous que le fichier est un fichier texte\n",
    "        try:\n",
    "            json_data = []\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                # Lire le fichier ligne par ligne et convertir en JSON\n",
    "                for line in f:\n",
    "                    data = line.strip().split(\"\\t\")  # Séparer les données par tabulation\n",
    "                    json_data.append(data)\n",
    "            \n",
    "            # Sauvegarder les données en JSON\n",
    "            json_filename = file_path.replace(\".txt\", \".json\")\n",
    "            with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                json.dump(json_data, json_file, indent=4)\n",
    "            print(f\"Fichier converti en JSON : {json_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement du fichier {file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur k : None\n",
      "Coordonnées : lat=None, lon=None\n",
      "t_1h : t_1h\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 01:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 02:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 03:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 04:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 05:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 06:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 07:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 08:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 09:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 10:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 11:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 12:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 13:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 14:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 15:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 16:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 17:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 18:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 19:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 20:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 21:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 22:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-01 23:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 00:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 01:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 02:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 03:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 04:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 05:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 06:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 07:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 08:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 09:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 10:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 11:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 12:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 13:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 14:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 15:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 16:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 17:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 18:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 19:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 20:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 21:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 22:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-02 23:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 00:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 01:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 02:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 03:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 04:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 05:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 06:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 07:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 08:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 09:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 10:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 11:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 12:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 13:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 14:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 15:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 16:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 17:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 18:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 19:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 20:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 21:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 22:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-03 23:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 00:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 01:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 02:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 03:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 04:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 05:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 06:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 07:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 08:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 09:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 10:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 11:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 12:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 13:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 14:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 15:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 16:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 17:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 18:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 19:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 20:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 21:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 22:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-04 23:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-05 00:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-05 01:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-05 02:00:00\n",
      "Valeur k : 0.0\n",
      "Coordonnées : lat=None, lon=459.0\n",
      "t_1h : 2020-01-05 03:00:00\n",
      "Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la grille à partir des latitudes et longitudes\n",
    "def creer_grille(lat_min, lat_max, lon_min, lon_max, step):\n",
    "    grille = []\n",
    "    latitudes = np.arange(lat_min, lat_max, step)\n",
    "    longitudes = np.arange(lon_min, lon_max, step)\n",
    "    \n",
    "    for i in range(len(latitudes) - 1):\n",
    "        for j in range(len(longitudes) - 1):\n",
    "            carre = {\n",
    "                \"id\": f\"{i}_{j}\",  # Identifiant unique pour chaque carré\n",
    "                \"lat_min\": latitudes[i],\n",
    "                \"lat_max\": latitudes[i + 1],\n",
    "                \"lon_min\": longitudes[j],\n",
    "                \"lon_max\": longitudes[j + 1]\n",
    "            }\n",
    "            grille.append(carre)\n",
    "    return grille\n",
    "\n",
    "# Fonction pour trouver le carré correspondant à un point\n",
    "def trouver_carre(lat, lon, grille):\n",
    "    for carre in grille:\n",
    "        if carre[\"lat_min\"] <= lat < carre[\"lat_max\"] and carre[\"lon_min\"] <= lon < carre[\"lon_max\"]:\n",
    "            return carre[\"id\"]\n",
    "    return None\n",
    "\n",
    "# Définir les limites de la grille\n",
    "lat_min, lat_max = 48.81, 48.92\n",
    "lon_min, lon_max = 2.255, 2.42\n",
    "step = 0.005  # Pas pour la grille, correspond à la taille d'un carré\n",
    "\n",
    "# Créer la grille\n",
    "grille = creer_grille(lat_min, lat_max, lon_min, lon_max, step)\n",
    "\n",
    "# Fonction pour extraire les données correctement\n",
    "def extraire_donnees(item):\n",
    "    champs = item[0].split(\";\")\n",
    "    \n",
    "    try:\n",
    "        # Vérifier si la valeur de k peut être convertie en float\n",
    "        k = champs[9] if champs[9] else None\n",
    "        lat = champs[5] if champs[5] else None  # Vérifier ici si lat est au bon indice\n",
    "        lon = champs[4] if champs[4] else None  # Vérifier ici si lon est au bon indice\n",
    "        t_1h = champs[6]\n",
    "        \n",
    "        # Tentative de conversion de k en float\n",
    "        k = float(k) if k and k.replace('.', '', 1).isdigit() else None\n",
    "        \n",
    "        # Tentative de conversion de lat et lon en float\n",
    "        lat = float(lat) if lat and lat.replace('.', '', 1).isdigit() else None\n",
    "        lon = float(lon) if lon and lon.replace('.', '', 1).isdigit() else None\n",
    "        \n",
    "        # Vérification des données extraites\n",
    "        print(f\"Valeur k : {k}\")\n",
    "        print(f\"Coordonnées : lat={lat}, lon={lon}\")\n",
    "        print(f\"t_1h : {t_1h}\")\n",
    "        \n",
    "        # Si lat, lon ou k sont invalides, retourner None\n",
    "        if lat is None or lon is None or k is None:\n",
    "            return None, None, None, None\n",
    "        return lat, lon, k, t_1h\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur d'extraction : {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "# Charger les données JSON\n",
    "with open(\"extracted_data/trafic_capteurs_2020_W00_20200101_20200108.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialiser le regroupement par carré et t_1h\n",
    "regroupement = {}\n",
    "\n",
    "# Limiter l'exécution aux 100 premières lignes pour tester\n",
    "for item in data[:100]:  # Test avec un sous-ensemble des données\n",
    "    lat, lon, k, t_1h = extraire_donnees(item)\n",
    "    \n",
    "    if lat is not None and lon is not None and k is not None and t_1h is not None:\n",
    "        carre_id = trouver_carre(lat, lon, grille)\n",
    "        \n",
    "        if carre_id is not None:\n",
    "            # Créer une clé composée de l'ID du carré et de l'horodatage t_1h\n",
    "            key = (carre_id, t_1h)\n",
    "            \n",
    "            if key not in regroupement:\n",
    "                regroupement[key] = {\"somme_k\": 0, \"count_k\": 0}\n",
    "            \n",
    "            regroupement[key][\"somme_k\"] += k\n",
    "            regroupement[key][\"count_k\"] += 1\n",
    "\n",
    "# Calcul des moyennes pour chaque carré et chaque t_1h\n",
    "resultats_final = []\n",
    "for key, contenu in regroupement.items():\n",
    "    carre_id, t_1h = key\n",
    "    somme_k = contenu[\"somme_k\"]\n",
    "    count_k = contenu[\"count_k\"]\n",
    "    moyenne_k = somme_k / count_k if count_k > 0 else None\n",
    "    resultats_final.append({\"carre_id\": carre_id, \"t_1h\": t_1h, \"moyenne_k\": moyenne_k})\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier JSON\n",
    "with open(\"moyennes_par_carre_et_t1h.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultats_final, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation de la table référentiel en csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé et sauvegardé sous : referentiel.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL du fichier CSV que vous voulez télécharger\n",
    "url = 'https://parisdata.opendatasoft.com/api/explore/v2.1/catalog/datasets/referentiel-comptages-routiers/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B'\n",
    "\n",
    "# Nom local sous lequel vous voulez sauvegarder le fichier\n",
    "local_filename = 'referentiel.csv'\n",
    "\n",
    "# Télécharger le fichier\n",
    "response = requests.get(url)\n",
    "\n",
    "# Vérifier si la demande a réussi (status_code 200)\n",
    "if response.status_code == 200:\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier téléchargé et sauvegardé sous : {local_filename}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement du fichier : {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifiant arc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6799</td>\n",
       "      <td>48.88610804018005</td>\n",
       "      <td>2.3060170797614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6839</td>\n",
       "      <td>48.882846124767354</td>\n",
       "      <td>2.309608336489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6381</td>\n",
       "      <td>48.88185021600981</td>\n",
       "      <td>2.313636877615184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240</td>\n",
       "      <td>48.867653082202935</td>\n",
       "      <td>2.362827833173667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5164</td>\n",
       "      <td>48.83748471020789</td>\n",
       "      <td>2.2572392666841106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6603</td>\n",
       "      <td>48.82680441725183</td>\n",
       "      <td>2.3040355371176604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6593</td>\n",
       "      <td>48.86194217627273</td>\n",
       "      <td>2.31342704120477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6813</td>\n",
       "      <td>48.85824539762091</td>\n",
       "      <td>2.314401975386383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4382</td>\n",
       "      <td>48.87468482154655</td>\n",
       "      <td>2.303280892510164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>269</td>\n",
       "      <td>48.86779977023447</td>\n",
       "      <td>2.314350336430965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifiant arc                 lat                  lon\n",
       "0             6799   48.88610804018005   2.3060170797614274\n",
       "1             6839  48.882846124767354    2.309608336489109\n",
       "2             6381   48.88185021600981    2.313636877615184\n",
       "3             1240  48.867653082202935    2.362827833173667\n",
       "4             5164   48.83748471020789   2.2572392666841106\n",
       "5             6603   48.82680441725183   2.3040355371176604\n",
       "6             6593   48.86194217627273     2.31342704120477\n",
       "7             6813   48.85824539762091    2.314401975386383\n",
       "8             4382   48.87468482154655    2.303280892510164\n",
       "9              269   48.86779977023447    2.314350336430965"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Charger le fichier du référentiel avec les informations géographiques\n",
    "geo_df = pd.read_csv(\"referentiel.csv\", delimiter=\";\")\n",
    "geo_df[['lat', 'lon']] = geo_df['geo_point_2d'].str.split(',', expand=True)\n",
    "geo_df = geo_df[['Identifiant arc','lat', 'lon']]\n",
    "# Afficher les premières lignes pour vérifier la structure\n",
    "geo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier trafic_capteurs_2020_W00_20200101_20200108.txt chargé avec succès\n",
      "   iu_ac    k                 t_1h\n",
      "0    799  0.0  2020-01-01 01:00:00\n",
      "1    799  0.0  2020-01-01 02:00:00\n",
      "2    799  0.0  2020-01-01 03:00:00\n",
      "3    799  0.0  2020-01-01 04:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trafic_df = pd.read_csv(\"extracted_data/trafic_capteurs_2020_W00_20200101_20200108.txt\", delimiter=\";\")\n",
    "    print(\"Fichier trafic_capteurs_2020_W00_20200101_20200108.txt chargé avec succès\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du fichier trafic_capteurs_2020_W00_20200101_20200108.txt : {e}\")\n",
    "\n",
    "trafic_df = trafic_df[['iu_ac','k','t_1h']]\n",
    "trafic_df ['k'] = trafic_df ['k'].fillna(0)\n",
    "print(trafic_df.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iu_ac</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6799</td>\n",
       "      <td>48.88610804018005</td>\n",
       "      <td>2.3060170797614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6839</td>\n",
       "      <td>48.882846124767354</td>\n",
       "      <td>2.309608336489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6381</td>\n",
       "      <td>48.88185021600981</td>\n",
       "      <td>2.313636877615184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240</td>\n",
       "      <td>48.867653082202935</td>\n",
       "      <td>2.362827833173667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iu_ac                 lat                  lon\n",
       "0   6799   48.88610804018005   2.3060170797614274\n",
       "1   6839  48.882846124767354    2.309608336489109\n",
       "2   6381   48.88185021600981    2.313636877615184\n",
       "3   1240  48.867653082202935    2.362827833173667"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.rename(columns={\"Identifiant arc\": \"iu_ac\"}, inplace=True)\n",
    "geo_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire la jointure sur un identifiant commun (par exemple, 'iu_ac')\n",
    "merged_df = pd.merge(trafic_df, geo_df, on='iu_ac', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iu_ac      int64\n",
      "k        float64\n",
      "t_1h      object\n",
      "lat       object\n",
      "lon       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Afficher les premières lignes du DataFrame fusionné\n",
    "merged_df.head(2)\n",
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour créer la grille à partir des latitudes et longitudes\n",
    "def creer_grille(lat_min, lat_max, lon_min, lon_max, step):\n",
    "    grille = []\n",
    "    latitudes = np.arange(lat_min, lat_max, step)\n",
    "    longitudes = np.arange(lon_min, lon_max, step)\n",
    "    \n",
    "    for i in range(len(latitudes) - 1):\n",
    "        for j in range(len(longitudes) - 1):\n",
    "            carre = {\n",
    "                \"id\": f\"{i}_{j}\",  # Identifiant unique pour chaque carré\n",
    "                \"lat_min\": latitudes[i],\n",
    "                \"lat_max\": latitudes[i + 1],\n",
    "                \"lon_min\": longitudes[j],\n",
    "                \"lon_max\": longitudes[j + 1]\n",
    "            }\n",
    "            grille.append(carre)\n",
    "    return grille\n",
    "\n",
    "# Fonction pour trouver le carré correspondant à un point\n",
    "def trouver_carre(lat, lon, grille):\n",
    "    if lat is None or lon is None:\n",
    "        return None\n",
    "    for carre in grille:\n",
    "        if carre[\"lat_min\"] <= lat < carre[\"lat_max\"] and carre[\"lon_min\"] <= lon < carre[\"lon_max\"]:\n",
    "            return carre[\"id\"]\n",
    "    return None\n",
    "\n",
    "# Définir les limites de la grille\n",
    "lat_min, lat_max = 48.81, 48.92\n",
    "lon_min, lon_max = 2.255, 2.42\n",
    "step = 0.005  # Pas pour la grille, correspond à la taille d'un carré\n",
    "\n",
    "# Créer la grille\n",
    "grille = creer_grille(lat_min, lat_max, lon_min, lon_max, step)\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour associer le carré à chaque ligne du DataFrame\n",
    "def associer_carres(df):\n",
    "    df['carre_id'] = df.apply(lambda row: trouver_carre(row['lat'], row['lon'], grille), axis=1)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iu_ac    k                 t_1h        lat       lon carre_id\n",
      "0    799  0.0  2020-01-01 01:00:00  48.820906  2.355258     2_20\n",
      "1    799  0.0  2020-01-01 02:00:00  48.820906  2.355258     2_20\n",
      "2    799  0.0  2020-01-01 03:00:00  48.820906  2.355258     2_20\n",
      "3    799  0.0  2020-01-01 04:00:00  48.820906  2.355258     2_20\n",
      "4    799  0.0  2020-01-01 05:00:00  48.820906  2.355258     2_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36012/1496085145.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df['carre_id'] = merged_df.apply(lambda row: trouver_carre(row['lat'], row['lon'], grille), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage des espaces dans lat et lon\n",
    "merged_df['lat'] = merged_df['lat'].str.strip()\n",
    "merged_df['lon'] = merged_df['lon'].str.strip()\n",
    "\n",
    "# Conversion en float avec gestion des erreurs\n",
    "merged_df['lat'] = pd.to_numeric(merged_df['lat'], errors='coerce')\n",
    "merged_df['lon'] = pd.to_numeric(merged_df['lon'], errors='coerce')\n",
    "\n",
    "# Supprimer les lignes avec des NaN dans lat ou lon\n",
    "merged_df = merged_df.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "# Appliquer la fonction pour associer les carrés\n",
    "merged_df['carre_id'] = merged_df.apply(lambda row: trouver_carre(row['lat'], row['lon'], grille), axis=1)\n",
    "\n",
    "# Supprimer les lignes où carre_id est NaN\n",
    "merged_df = merged_df.dropna(subset=['carre_id'])\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carre_id</th>\n",
       "      <th>t_1h</th>\n",
       "      <th>moyenne_k</th>\n",
       "      <th>somme_k</th>\n",
       "      <th>count_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 04:00:00</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 05:00:00</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 06:00:00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 07:00:00</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 08:00:00</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 09:00:00</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_16</td>\n",
       "      <td>2020-01-01 10:00:00</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  carre_id                 t_1h  moyenne_k  somme_k  count_k\n",
       "0     0_16  2020-01-01 01:00:00      0.650     1.30        2\n",
       "1     0_16  2020-01-01 02:00:00      0.725     1.45        2\n",
       "2     0_16  2020-01-01 03:00:00      0.925     1.85        2\n",
       "3     0_16  2020-01-01 04:00:00      1.125     2.25        2\n",
       "4     0_16  2020-01-01 05:00:00      0.825     1.65        2\n",
       "5     0_16  2020-01-01 06:00:00      0.875     1.75        2\n",
       "6     0_16  2020-01-01 07:00:00      0.725     1.45        2\n",
       "7     0_16  2020-01-01 08:00:00      0.475     0.95        2\n",
       "8     0_16  2020-01-01 09:00:00      0.475     0.95        2\n",
       "9     0_16  2020-01-01 10:00:00      0.700     1.40        2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regrouper les données par carré et t_1h, puis calculer la moyenne de k\n",
    "resultats_groupes = merged_df.groupby(['carre_id', 't_1h']).agg(\n",
    "    moyenne_k=('k', 'mean'),\n",
    "    somme_k=('k', 'sum'),\n",
    "    count_k=('k', 'count')\n",
    ").reset_index()\n",
    "\n",
    "resultats_groupes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h.csv'\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les résultats dans un fichier CSV\n",
    "resultats_groupes.to_csv('moyennes_par_carre_et_t1h.csv', index=False)\n",
    "\n",
    "print(\"Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
