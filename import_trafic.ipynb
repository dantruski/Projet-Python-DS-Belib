{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données de comptage routier\n",
    "\n",
    "Les données de comptage routier sont disponibles en téléchargement sur Paris OpenData. Leur volume important nous oblige à choisir une seule semaine à étudier : du 22/01/2020 au 29/01/2020 (voir main.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé : comptages_routiers_2020.zip\n",
      "Deux premiers fichiers extraits : ['trafic_capteurs_2020_W03_20200122_20200129.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# URL du fichier ZIP\n",
    "url = \"https://opendata.paris.fr/api/datasets/1.0/comptages-routiers-permanents-historique/attachments/opendata_txt_2020_zip/\"\n",
    "\n",
    "# Nom local du fichier ZIP\n",
    "zip_filename = \"comptages_routiers_2020.zip\"\n",
    "\n",
    "# Dossier où extraire les fichiers\n",
    "output_folder = \"extracted_data\"\n",
    "\n",
    "# Étape 1 : Télécharger le fichier ZIP\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(zip_filename, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier téléchargé : {zip_filename}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement : {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# Étape 2 : Extraire le contenu du fichier ZIP\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    all_files = zip_ref.namelist()[3:4]  # Limiter à 2 fichiers\n",
    "    for file in all_files:\n",
    "        zip_ref.extract(file, output_folder)\n",
    "    print(f\"Deux premiers fichiers extraits : {all_files}\")\n",
    "\n",
    "# Étape 3 : Convertir les fichiers texte en JSON\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(output_folder, file)\n",
    "    if file.endswith(\".txt\"):  # Assurez-vous que le fichier est un fichier texte\n",
    "        try:\n",
    "            json_data = []\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                # Lire le fichier ligne par ligne et convertir en JSON\n",
    "                for line in f:\n",
    "                    data = line.strip().split(\"\\t\")  # Séparer les données par tabulation\n",
    "                    json_data.append(data)\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement du fichier {file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation de la table référentiel en csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé et sauvegardé sous : referentiel.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# URL du fichier CSV que vous voulez télécharger\n",
    "url = 'https://parisdata.opendatasoft.com/api/explore/v2.1/catalog/datasets/referentiel-comptages-routiers/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B'\n",
    "\n",
    "# Nom local sous lequel vous voulez sauvegarder le fichier\n",
    "local_filename = 'csv/referentiel.csv'\n",
    "\n",
    "# Télécharger le fichier\n",
    "response = requests.get(url)\n",
    "\n",
    "# Vérifier si la demande a réussi (status_code 200)\n",
    "if response.status_code == 200:\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Fichier téléchargé et sauvegardé sous : {local_filename}\")\n",
    "else:\n",
    "    print(f\"Erreur lors du téléchargement du fichier : {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifiant arc</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6799</td>\n",
       "      <td>48.88610804018005</td>\n",
       "      <td>2.3060170797614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6839</td>\n",
       "      <td>48.882846124767354</td>\n",
       "      <td>2.309608336489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6381</td>\n",
       "      <td>48.88185021600981</td>\n",
       "      <td>2.313636877615184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240</td>\n",
       "      <td>48.867653082202935</td>\n",
       "      <td>2.362827833173667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5164</td>\n",
       "      <td>48.83748471020789</td>\n",
       "      <td>2.2572392666841106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6603</td>\n",
       "      <td>48.82680441725183</td>\n",
       "      <td>2.3040355371176604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6593</td>\n",
       "      <td>48.86194217627273</td>\n",
       "      <td>2.31342704120477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6813</td>\n",
       "      <td>48.85824539762091</td>\n",
       "      <td>2.314401975386383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4382</td>\n",
       "      <td>48.87468482154655</td>\n",
       "      <td>2.303280892510164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>269</td>\n",
       "      <td>48.86779977023447</td>\n",
       "      <td>2.314350336430965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifiant arc                 lat                  lon\n",
       "0             6799   48.88610804018005   2.3060170797614274\n",
       "1             6839  48.882846124767354    2.309608336489109\n",
       "2             6381   48.88185021600981    2.313636877615184\n",
       "3             1240  48.867653082202935    2.362827833173667\n",
       "4             5164   48.83748471020789   2.2572392666841106\n",
       "5             6603   48.82680441725183   2.3040355371176604\n",
       "6             6593   48.86194217627273     2.31342704120477\n",
       "7             6813   48.85824539762091    2.314401975386383\n",
       "8             4382   48.87468482154655    2.303280892510164\n",
       "9              269   48.86779977023447    2.314350336430965"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Charger le fichier du référentiel avec les informations géographiques\n",
    "geo_df = pd.read_csv(\"csv/referentiel.csv\", delimiter=\";\")\n",
    "geo_df[['lat', 'lon']] = geo_df['geo_point_2d'].str.split(',', expand=True)\n",
    "geo_df = geo_df[['Identifiant arc','lat', 'lon']]\n",
    "# Afficher les premières lignes pour vérifier la structure\n",
    "geo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier trafic_capteurs_2020_W03_20200122_20200129.txt chargé avec succès\n",
      "   iu_ac        k                 t_1h\n",
      "0    799  0.28167  2020-01-22 01:00:00\n",
      "1    799  0.14611  2020-01-22 02:00:00\n",
      "2    799  0.10333  2020-01-22 03:00:00\n",
      "3    799  0.02778  2020-01-22 04:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trafic_df = pd.read_csv(\"extracted_data/trafic_capteurs_2020_W03_20200122_20200129.txt\", delimiter=\";\")\n",
    "    print(\"Fichier trafic_capteurs_2020_W03_20200122_20200129.txt chargé avec succès\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du fichier trafic_capteurs_2020_W03_20200122_20200129.txt : {e}\")\n",
    "\n",
    "trafic_df = trafic_df[['iu_ac','k','t_1h']]\n",
    "trafic_df ['k'] = trafic_df ['k'].fillna(0)\n",
    "print(trafic_df.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iu_ac</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6799</td>\n",
       "      <td>48.88610804018005</td>\n",
       "      <td>2.3060170797614274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6839</td>\n",
       "      <td>48.882846124767354</td>\n",
       "      <td>2.309608336489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6381</td>\n",
       "      <td>48.88185021600981</td>\n",
       "      <td>2.313636877615184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1240</td>\n",
       "      <td>48.867653082202935</td>\n",
       "      <td>2.362827833173667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iu_ac                 lat                  lon\n",
       "0   6799   48.88610804018005   2.3060170797614274\n",
       "1   6839  48.882846124767354    2.309608336489109\n",
       "2   6381   48.88185021600981    2.313636877615184\n",
       "3   1240  48.867653082202935    2.362827833173667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.rename(columns={\"Identifiant arc\": \"iu_ac\"}, inplace=True)\n",
    "geo_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire la jointure sur un identifiant commun (par exemple, 'iu_ac')\n",
    "merged_df = pd.merge(trafic_df, geo_df, on='iu_ac', how='left')\n",
    "\n",
    "merged_df = merged_df[['k','t_1h','lat','lon']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>t_1h</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28167</td>\n",
       "      <td>2020-01-22 01:00:00</td>\n",
       "      <td>48.8209057931176</td>\n",
       "      <td>2.3552584484462633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.14611</td>\n",
       "      <td>2020-01-22 02:00:00</td>\n",
       "      <td>48.8209057931176</td>\n",
       "      <td>2.3552584484462633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k                 t_1h               lat                  lon\n",
       "0  0.28167  2020-01-22 01:00:00  48.8209057931176   2.3552584484462633\n",
       "1  0.14611  2020-01-22 02:00:00  48.8209057931176   2.3552584484462633"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les premières lignes du DataFrame fusionné\n",
    "merged_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"csv/traffic2229.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger le fichier GeoJSON des arrondissements de Paris\n",
    "arrondissements_geojson = \"arrondissements.geojson\"  \n",
    "arrondissements_gdf = gpd.read_file(arrondissements_geojson)  # Charger les arrondissements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les zones de notre découpage (appelées 'carrés') ainsi : chaque carré est délimité par les valeurs des latitudes uniformément réparties de 48.81 à 48.92 avec un pas de latitude de 0.005 (48.810, 48.815, 48.820,...,48.910, 48.915, 48.920). De même les longitudes sont réparties entre 2.255 et 2.420 avec le même pas (2.255, 2.260,...,2.415, 2.420).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iu_ac        k                 t_1h        lat       lon carre_id     lati  \\\n",
      "0    799  0.28167  2020-01-22 01:00:00  48.820906  2.355258     2_20  48.8225   \n",
      "1    799  0.14611  2020-01-22 02:00:00  48.820906  2.355258     2_20  48.8225   \n",
      "2    799  0.10333  2020-01-22 03:00:00  48.820906  2.355258     2_20  48.8225   \n",
      "3    799  0.02778  2020-01-22 04:00:00  48.820906  2.355258     2_20  48.8225   \n",
      "4    799  0.11778  2020-01-22 05:00:00  48.820906  2.355258     2_20  48.8225   \n",
      "\n",
      "     long  \n",
      "0  2.3575  \n",
      "1  2.3575  \n",
      "2  2.3575  \n",
      "3  2.3575  \n",
      "4  2.3575  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fonction pour créer la grille à partir des latitudes et longitudes\n",
    "def creer_grille(lat_min, lat_max, lon_min, lon_max, step):\n",
    "    grille = []\n",
    "    latitudes = np.arange(lat_min, lat_max, step)\n",
    "    longitudes = np.arange(lon_min, lon_max, step)\n",
    "    \n",
    "    for i in range(len(latitudes) - 1):\n",
    "        for j in range(len(longitudes) - 1):\n",
    "            carre = {\n",
    "                \"id\": f\"{i}_{j}\",  # Identifiant unique pour chaque carré\n",
    "                \"lat_min\": latitudes[i],\n",
    "                \"lat_max\": latitudes[i + 1],\n",
    "                \"lon_min\": longitudes[j],\n",
    "                \"lon_max\": longitudes[j + 1],\n",
    "                \"lati\": latitudes[i] + 0.005/2,  # Centre du carré\n",
    "                \"long\": longitudes[j] +  0.005/2,  # Centre du carré\n",
    "            }\n",
    "            grille.append(carre)\n",
    "    return grille\n",
    "\n",
    "# Fonction pour trouver le carré correspondant à un point\n",
    "def trouver_carre(lat, lon, grille):\n",
    "    center_point = Point(lon, lat)\n",
    "    if pd.isnull(lat) or pd.isnull(lon):  # Vérifier si lat ou lon est NaN\n",
    "        return None, None, None\n",
    "    for carre in grille:\n",
    "        if carre[\"lat_min\"] <= lat < carre[\"lat_max\"] and carre[\"lon_min\"] <= lon < carre[\"lon_max\"]:\n",
    "            #if not arrondissements_gdf.geometry.unary_union.contains(center_point):\n",
    "             #   continue  # Ignorer les carrés hors des arrondissements de Paris\n",
    "            return carre[\"id\"], carre[\"lati\"], carre[\"long\"]\n",
    "    return None, None, None\n",
    "\n",
    "# Fonction pour associer le carré à chaque ligne du DataFrame\n",
    "def associer_carres(df, grille):\n",
    "    # Appliquer la fonction trouver_carre à chaque ligne\n",
    "    df[['carre_id', 'lati', 'long']] = df.apply(\n",
    "        lambda row: pd.Series(trouver_carre(row['lat'], row['lon'], grille)), axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Définir les limites de la grille\n",
    "lat_min, lat_max = 48.81, 48.92\n",
    "lon_min, lon_max = 2.255, 2.42\n",
    "step = 0.005  # Taille d'un carré\n",
    "\n",
    "# Créer la grille\n",
    "grille = creer_grille(lat_min, lat_max, lon_min, lon_max, step)\n",
    "\n",
    "\n",
    "# Nettoyer les colonnes lat et lon\n",
    "merged_df['lat'] = merged_df['lat'].astype(str).str.strip()\n",
    "merged_df['lon'] = merged_df['lon'].astype(str).str.strip()\n",
    "\n",
    "# Convertir les colonnes lat et lon en float\n",
    "merged_df['lat'] = pd.to_numeric(merged_df['lat'], errors='coerce')\n",
    "merged_df['lon'] = pd.to_numeric(merged_df['lon'], errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "# Associer les carrés\n",
    "merged_df = associer_carres(merged_df, grille)\n",
    "\n",
    "# Supprimer les lignes où carre_id est NaN\n",
    "merged_df = merged_df.dropna(subset=['carre_id'])\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    613704.000000\n",
      "mean          4.115966\n",
      "std           8.345619\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.522230\n",
      "75%           4.768890\n",
      "max          99.299450\n",
      "Name: k, dtype: float64\n",
      "        iu_ac         k                 t_1h        lat       lon carre_id  \\\n",
      "19        799  10.48945  2020-01-22 20:00:00  48.820906  2.355258     2_20   \n",
      "63        799  10.19667  2020-01-24 16:00:00  48.820906  2.355258     2_20   \n",
      "64        799  13.07278  2020-01-24 17:00:00  48.820906  2.355258     2_20   \n",
      "161       799  17.36500  2020-01-28 18:00:00  48.820906  2.355258     2_20   \n",
      "374      4950  11.21444  2020-01-23 15:00:00  48.880555  2.369004    14_22   \n",
      "...       ...       ...                  ...        ...       ...      ...   \n",
      "620751    844  13.17667  2020-01-28 16:00:00  48.820146  2.365537     2_22   \n",
      "620752    844  28.45167  2020-01-28 17:00:00  48.820146  2.365537     2_22   \n",
      "620753    844  50.47111  2020-01-28 18:00:00  48.820146  2.365537     2_22   \n",
      "620754    844  54.48611  2020-01-28 19:00:00  48.820146  2.365537     2_22   \n",
      "620755    844  30.99389  2020-01-28 20:00:00  48.820146  2.365537     2_22   \n",
      "\n",
      "           lati    long  \n",
      "19      48.8225  2.3575  \n",
      "63      48.8225  2.3575  \n",
      "64      48.8225  2.3575  \n",
      "161     48.8225  2.3575  \n",
      "374     48.8825  2.3675  \n",
      "...         ...     ...  \n",
      "620751  48.8225  2.3675  \n",
      "620752  48.8225  2.3675  \n",
      "620753  48.8225  2.3675  \n",
      "620754  48.8225  2.3675  \n",
      "620755  48.8225  2.3675  \n",
      "\n",
      "[73093 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['k'].describe())\n",
    "print(merged_df[merged_df['k'] > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.254259999999995\n",
      "count    72576.000000\n",
      "mean         4.330124\n",
      "std          5.311477\n",
      "min          0.000000\n",
      "25%          0.759427\n",
      "50%          2.535592\n",
      "75%          5.876576\n",
      "max         62.254260\n",
      "Name: moyenne_k, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Regrouper les données par carré et t_1h, puis calculer la moyenne de k\n",
    "resultats_groupes = merged_df.groupby(['t_1h','carre_id']).agg(\n",
    "    moyenne_k=('k', 'mean'),\n",
    "    somme_k=('k', 'sum'),\n",
    "    count_k=('k', 'count'),\n",
    "    lati= ('lati', 'mean'),\n",
    "    long= ('long', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(resultats_groupes['moyenne_k'].max())\n",
    "resultats_groupes.head(10)\n",
    "print(resultats_groupes['moyenne_k'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h2229.csv'\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les résultats dans un fichier CSV\n",
    "resultats_groupes.to_csv('csv/moyennes_par_carre_et_t1h2229.csv', index=False)\n",
    "\n",
    "print(\"Moyennes calculées et sauvegardées dans 'moyennes_par_carre_et_t1h2229.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
